# 未命名

Abstract—Visual saliency is a fundamental problem in both
cognitive and computational sciences, including computer vision.
In this paper, we discover that a high-quality visual saliency
model can be learned from multiscale features extracted using
deep convolutional neural networks (CNNs), which have had
many successes in visual recognition tasks. For learning such
saliency models, we introduce a neural network architecture,
which has fully connected layers on top of CNNs responsible for
feature extraction at three different scales. The penultimate layer
of our neural network has been confirmed to be a discriminative
high-level feature vector for saliency detection, which we call
deep contrast feature. To generate a more robust feature, we
integrate handcrafted low-level features with our deep contrast
feature. To promote further research and evaluation of visual
saliency models, we also construct a new large database of
4447 challenging images and their pixelwise saliency annotations.
Experimental results demonstrate that our proposed method is
capable of achieving state-of-the-art performance on all public
benchmarks, improving the F-measure by 6.12% and 10.0%
respectively on the DUT-OMRON dataset and our new dataset
(HKU-IS), and lowering the mean absolute error by 9% and
35.3% respectively on these two datasets.
Index Terms—Convolutional Neural Networks, Saliency Detec-
tion, Deep Contrast Feature.

摘要——视觉显著性是两者中的一个基本问题
认知和计算科学，包括计算机视觉。
在本文中，我们发现高质量的视觉显著性
模型可以从使用
深度卷积神经网络
在视觉识别任务中取得了许多成功。为了学习
显著性模型，我们引入了一种神经网络架构，
其在负责
三个不同尺度的特征提取。倒数第二层
我们的神经网络的
用于显著性检测的高级特征向量，我们称之为
深度对比特征。为了生成更健壮的特征，我们
将手工制作的低级功能与我们的深度对比相结合
特色促进对视觉的进一步研究和评价
显著性模型，我们还构建了一个新的大型数据库
4447个具有挑战性的图像及其逐像素显著性注释。
实验结果表明，我们提出的方法是
能够在所有公众中实现最先进的性能
基准，将F-measure提高了6.12%和10.0%
分别在DUT-OMRON数据集和我们的新数据集上
（HKU-IS），并将平均绝对误差降低9%
分别为35.3%。
索引项——卷积神经网络，显著性检测-
深度对比功能。
